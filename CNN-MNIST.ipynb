{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An easy CNN network for digital classification.Author SUNNK.Time 2017/7/22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "training_iters = 2000000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "n_input = 784 \n",
    "n_classes = 10 \n",
    "dropout = 0.75  #dropout是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。注意是暂时，\n",
    "                            #对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = { #关于卷积神经网络参数计算问题可以参考http://blog.csdn.net/dcxhun3/article/details/46878999\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数： 12800, 损失= 20697.851562, 训练准确率= 0.30469\n",
      "迭代次数： 25600, 损失= 12963.962891, 训练准确率= 0.42188\n",
      "迭代次数： 38400, 损失= 6155.549316, 训练准确率= 0.67969\n",
      "迭代次数： 51200, 损失= 6231.414062, 训练准确率= 0.75781\n",
      "迭代次数： 64000, 损失= 3723.636230, 训练准确率= 0.83594\n",
      "迭代次数： 76800, 损失= 2679.205078, 训练准确率= 0.84375\n",
      "迭代次数： 89600, 损失= 3563.668945, 训练准确率= 0.86719\n",
      "迭代次数： 102400, 损失= 3190.264893, 训练准确率= 0.84375\n",
      "迭代次数： 115200, 损失= 2269.433594, 训练准确率= 0.85938\n",
      "迭代次数： 128000, 损失= 1687.265137, 训练准确率= 0.88281\n",
      "迭代次数： 140800, 损失= 2120.260986, 训练准确率= 0.89062\n",
      "迭代次数： 153600, 损失= 2463.311035, 训练准确率= 0.88281\n",
      "迭代次数： 166400, 损失= 2155.946777, 训练准确率= 0.90625\n",
      "迭代次数： 179200, 损失= 900.847290, 训练准确率= 0.90625\n",
      "迭代次数： 192000, 损失= 4498.732422, 训练准确率= 0.86719\n",
      "迭代次数： 204800, 损失= 957.868042, 训练准确率= 0.95312\n",
      "迭代次数： 217600, 损失= 2042.963379, 训练准确率= 0.89062\n",
      "迭代次数： 230400, 损失= 1005.500305, 训练准确率= 0.92969\n",
      "迭代次数： 243200, 损失= 542.450439, 训练准确率= 0.95312\n",
      "迭代次数： 256000, 损失= 1956.842773, 训练准确率= 0.88281\n",
      "迭代次数： 268800, 损失= 1372.397217, 训练准确率= 0.93750\n",
      "迭代次数： 281600, 损失= 970.156677, 训练准确率= 0.92969\n",
      "迭代次数： 294400, 损失= 1479.459473, 训练准确率= 0.92188\n",
      "迭代次数： 307200, 损失= 636.891907, 训练准确率= 0.94531\n",
      "迭代次数： 320000, 损失= 854.873535, 训练准确率= 0.95312\n",
      "迭代次数： 332800, 损失= 743.052002, 训练准确率= 0.94531\n",
      "迭代次数： 345600, 损失= 1029.917725, 训练准确率= 0.93750\n",
      "迭代次数： 358400, 损失= 364.272949, 训练准确率= 0.96875\n",
      "迭代次数： 371200, 损失= 1238.627930, 训练准确率= 0.92969\n",
      "迭代次数： 384000, 损失= 906.278320, 训练准确率= 0.94531\n",
      "迭代次数： 396800, 损失= 957.008545, 训练准确率= 0.92969\n",
      "迭代次数： 409600, 损失= 1077.072998, 训练准确率= 0.94531\n",
      "迭代次数： 422400, 损失= 1157.301880, 训练准确率= 0.92969\n",
      "迭代次数： 435200, 损失= 934.732666, 训练准确率= 0.92969\n",
      "迭代次数： 448000, 损失= 1258.443848, 训练准确率= 0.94531\n",
      "迭代次数： 460800, 损失= 166.424820, 训练准确率= 0.97656\n",
      "迭代次数： 473600, 损失= 959.820435, 训练准确率= 0.92969\n",
      "迭代次数： 486400, 损失= 612.107300, 训练准确率= 0.96875\n",
      "迭代次数： 499200, 损失= 424.944641, 训练准确率= 0.96875\n",
      "迭代次数： 512000, 损失= 596.901550, 训练准确率= 0.93750\n",
      "迭代次数： 524800, 损失= 334.806091, 训练准确率= 0.95312\n",
      "迭代次数： 537600, 损失= 1274.822754, 训练准确率= 0.92969\n",
      "迭代次数： 550400, 损失= 1128.347656, 训练准确率= 0.93750\n",
      "迭代次数： 563200, 损失= 473.211029, 训练准确率= 0.93750\n",
      "迭代次数： 576000, 损失= 567.061768, 训练准确率= 0.94531\n",
      "迭代次数： 588800, 损失= 594.832336, 训练准确率= 0.96094\n",
      "迭代次数： 601600, 损失= 501.644287, 训练准确率= 0.96094\n",
      "迭代次数： 614400, 损失= 407.233704, 训练准确率= 0.96094\n",
      "迭代次数： 627200, 损失= 804.047119, 训练准确率= 0.92969\n",
      "迭代次数： 640000, 损失= 737.294861, 训练准确率= 0.94531\n",
      "迭代次数： 652800, 损失= 256.537048, 训练准确率= 0.96875\n",
      "迭代次数： 665600, 损失= 311.476074, 训练准确率= 0.96875\n",
      "迭代次数： 678400, 损失= 370.679626, 训练准确率= 0.96094\n",
      "迭代次数： 691200, 损失= 433.483093, 训练准确率= 0.97656\n",
      "迭代次数： 704000, 损失= 544.046692, 训练准确率= 0.96094\n",
      "迭代次数： 716800, 损失= 139.944885, 训练准确率= 0.97656\n",
      "迭代次数： 729600, 损失= 636.481934, 训练准确率= 0.96094\n",
      "迭代次数： 742400, 损失= 120.080597, 训练准确率= 0.99219\n",
      "迭代次数： 755200, 损失= 354.089661, 训练准确率= 0.96875\n",
      "迭代次数： 768000, 损失= 283.773376, 训练准确率= 0.98438\n",
      "迭代次数： 780800, 损失= 251.645950, 训练准确率= 0.98438\n",
      "迭代次数： 793600, 损失= 354.104523, 训练准确率= 0.96094\n",
      "迭代次数： 806400, 损失= 134.540802, 训练准确率= 0.99219\n",
      "迭代次数： 819200, 损失= 199.107117, 训练准确率= 0.98438\n",
      "迭代次数： 832000, 损失= 174.453369, 训练准确率= 0.97656\n",
      "迭代次数： 844800, 损失= 424.514587, 训练准确率= 0.95312\n",
      "迭代次数： 857600, 损失= 294.107605, 训练准确率= 0.95312\n",
      "迭代次数： 870400, 损失= 122.829498, 训练准确率= 0.97656\n",
      "迭代次数： 883200, 损失= 272.336365, 训练准确率= 0.97656\n",
      "迭代次数： 896000, 损失= 214.527756, 训练准确率= 0.97656\n",
      "迭代次数： 908800, 损失= 111.521126, 训练准确率= 0.96875\n",
      "迭代次数： 921600, 损失= 129.680618, 训练准确率= 0.97656\n",
      "迭代次数： 934400, 损失= 398.133118, 训练准确率= 0.96094\n",
      "迭代次数： 947200, 损失= 253.333954, 训练准确率= 0.95312\n",
      "迭代次数： 960000, 损失= 44.385178, 训练准确率= 0.98438\n",
      "迭代次数： 972800, 损失= 173.699829, 训练准确率= 0.96875\n",
      "迭代次数： 985600, 损失= 61.797501, 训练准确率= 0.96875\n",
      "迭代次数： 998400, 损失= 231.961578, 训练准确率= 0.97656\n",
      "迭代次数： 1011200, 损失= 108.621857, 训练准确率= 0.97656\n",
      "迭代次数： 1024000, 损失= 227.039474, 训练准确率= 0.96875\n",
      "迭代次数： 1036800, 损失= 268.575775, 训练准确率= 0.95312\n",
      "迭代次数： 1049600, 损失= 24.873199, 训练准确率= 0.98438\n",
      "迭代次数： 1062400, 损失= 292.068542, 训练准确率= 0.98438\n",
      "迭代次数： 1075200, 损失= 226.387115, 训练准确率= 0.97656\n",
      "迭代次数： 1088000, 损失= 437.336121, 训练准确率= 0.95312\n",
      "迭代次数： 1100800, 损失= 33.264847, 训练准确率= 0.99219\n",
      "迭代次数： 1113600, 损失= 184.201965, 训练准确率= 0.97656\n",
      "迭代次数： 1126400, 损失= 103.912796, 训练准确率= 0.98438\n",
      "迭代次数： 1139200, 损失= 195.621170, 训练准确率= 0.98438\n",
      "迭代次数： 1152000, 损失= 155.693024, 训练准确率= 0.97656\n",
      "迭代次数： 1164800, 损失= 102.684601, 训练准确率= 0.98438\n",
      "迭代次数： 1177600, 损失= 32.106049, 训练准确率= 0.98438\n",
      "迭代次数： 1190400, 损失= 125.917366, 训练准确率= 0.96094\n",
      "迭代次数： 1203200, 损失= 324.820068, 训练准确率= 0.96094\n",
      "迭代次数： 1216000, 损失= 81.787605, 训练准确率= 0.97656\n",
      "迭代次数： 1228800, 损失= 98.374619, 训练准确率= 0.99219\n",
      "迭代次数： 1241600, 损失= 201.219574, 训练准确率= 0.97656\n",
      "迭代次数： 1254400, 损失= 136.915070, 训练准确率= 0.97656\n",
      "迭代次数： 1267200, 损失= 138.140503, 训练准确率= 0.98438\n",
      "迭代次数： 1280000, 损失= 138.671143, 训练准确率= 0.96875\n",
      "迭代次数： 1292800, 损失= 105.424011, 训练准确率= 0.96875\n",
      "迭代次数： 1305600, 损失= 82.250992, 训练准确率= 0.99219\n",
      "迭代次数： 1318400, 损失= 154.609589, 训练准确率= 0.96875\n",
      "迭代次数： 1331200, 损失= 34.866882, 训练准确率= 0.97656\n",
      "迭代次数： 1344000, 损失= 94.952820, 训练准确率= 0.99219\n",
      "迭代次数： 1356800, 损失= 172.236053, 训练准确率= 0.97656\n",
      "迭代次数： 1369600, 损失= 64.270592, 训练准确率= 0.98438\n",
      "迭代次数： 1382400, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1395200, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1408000, 损失= 179.388031, 训练准确率= 0.97656\n",
      "迭代次数： 1420800, 损失= 217.144073, 训练准确率= 0.99219\n",
      "迭代次数： 1433600, 损失= 237.360275, 训练准确率= 0.96094\n",
      "迭代次数： 1446400, 损失= 46.407532, 训练准确率= 0.98438\n",
      "迭代次数： 1459200, 损失= 61.101738, 训练准确率= 0.97656\n",
      "迭代次数： 1472000, 损失= 101.221687, 训练准确率= 0.99219\n",
      "迭代次数： 1484800, 损失= 131.829712, 训练准确率= 0.99219\n",
      "迭代次数： 1497600, 损失= 127.103897, 训练准确率= 0.96875\n",
      "迭代次数： 1510400, 损失= 54.287308, 训练准确率= 0.97656\n",
      "迭代次数： 1523200, 损失= 116.304489, 训练准确率= 0.96875\n",
      "迭代次数： 1536000, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1548800, 损失= 30.901695, 训练准确率= 0.99219\n",
      "迭代次数： 1561600, 损失= 167.963318, 训练准确率= 0.98438\n",
      "迭代次数： 1574400, 损失= 46.036079, 训练准确率= 0.98438\n",
      "迭代次数： 1587200, 损失= 215.518677, 训练准确率= 0.96094\n",
      "迭代次数： 1600000, 损失= 224.290176, 训练准确率= 0.98438\n",
      "迭代次数： 1612800, 损失= 4.063766, 训练准确率= 0.99219\n",
      "迭代次数： 1625600, 损失= 103.744446, 训练准确率= 0.97656\n",
      "迭代次数： 1638400, 损失= 157.736404, 训练准确率= 0.97656\n",
      "迭代次数： 1651200, 损失= 115.820831, 训练准确率= 0.97656\n",
      "迭代次数： 1664000, 损失= 90.963989, 训练准确率= 0.97656\n",
      "迭代次数： 1676800, 损失= 14.206684, 训练准确率= 0.98438\n",
      "迭代次数： 1689600, 损失= 125.983353, 训练准确率= 0.96094\n",
      "迭代次数： 1702400, 损失= 168.606171, 训练准确率= 0.97656\n",
      "迭代次数： 1715200, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1728000, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1740800, 损失= 73.300209, 训练准确率= 0.97656\n",
      "迭代次数： 1753600, 损失= 17.281548, 训练准确率= 0.99219\n",
      "迭代次数： 1766400, 损失= 46.108521, 训练准确率= 0.98438\n",
      "迭代次数： 1779200, 损失= 3.753845, 训练准确率= 0.99219\n",
      "迭代次数： 1792000, 损失= 26.050976, 训练准确率= 0.98438\n",
      "迭代次数： 1804800, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1817600, 损失= 82.621750, 训练准确率= 0.98438\n",
      "迭代次数： 1830400, 损失= 57.083832, 训练准确率= 0.98438\n",
      "迭代次数： 1843200, 损失= 40.304993, 训练准确率= 0.98438\n",
      "迭代次数： 1856000, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1868800, 损失= 71.855698, 训练准确率= 0.99219\n",
      "迭代次数： 1881600, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1894400, 损失= 90.923477, 训练准确率= 0.98438\n",
      "迭代次数： 1907200, 损失= 167.732819, 训练准确率= 0.98438\n",
      "迭代次数： 1920000, 损失= 8.665726, 训练准确率= 0.98438\n",
      "迭代次数： 1932800, 损失= 0.000000, 训练准确率= 1.00000\n",
      "迭代次数： 1945600, 损失= 112.041695, 训练准确率= 0.98438\n",
      "迭代次数： 1958400, 损失= 25.888100, 训练准确率= 0.98438\n",
      "迭代次数： 1971200, 损失= 5.498466, 训练准确率= 0.99219\n",
      "迭代次数： 1984000, 损失= 3.139023, 训练准确率= 0.99219\n",
      "迭代次数： 1996800, 损失= 70.035110, 训练准确率= 0.99219\n",
      "训练完成\n",
      "('\\xe6\\xb5\\x8b\\xe8\\xaf\\x95\\xe5\\x87\\x86\\xe7\\xa1\\xae\\xe7\\x8e\\x87:', 0.98046875)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            \n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"迭代次数： \" + str(step*batch_size) + \", 损失= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", 训练准确率= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"训练完成\")\n",
    "\n",
    "    print(\"测试准确率:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
